{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Credit Default Model\n",
    "Classification algorithm that tries to identify creditworthy creditors when evaluating new clients. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--TABLE OF CONTENTS-->\n",
    "## Contents:\n",
    "- [Data exploration and preparation](#Data)\n",
    "- [Feature Engineering](#Feature)\n",
    "  - [Feature Description](#Descr)\n",
    "  - [Encoding](#Encoding)\n",
    "  - [Taking a closer look at each feature](#Taking)\n",
    "  - [Scaling and Splitting the dataset](#Splitting)\n",
    "- [Model Training](#Model)\n",
    "  - [Random Forest](#Random)\n",
    "  - [XGBoost](#XGB)\n",
    "  - [Logistic Regression](#Logistic)\n",
    "  - [Nearest Neighbors](#Nearest)\n",
    "- [Model determination](#Model)\n",
    "  - [Random Forest](#Random2)\n",
    "  - [XGBoost](#XGB2)\n",
    "  - [Logistic Regression](#Logistic2)\n",
    "  - [Nearest Neighbors](#Nearest2)\n",
    "- [Model Evaluation](#Test)\n",
    "  - [Feature Analysis](#Feature2)\n",
    "- [Neural Networks](#Neural)\n",
    "- [Bias Audit](#Bias)\n",
    "- [Final conclusion and remarks](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix,  ConfusionMatrixDisplay \n",
    "from sklearn.inspection import permutation_importance\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import Sequential, layers, initializers, regularizers, losses, callbacks, optimizers\n",
    "#from aequitas.group import Group\n",
    "#from aequitas.bias import Bias\n",
    "#from aequitas.fairness import Fairness\n",
    "#from aequitas.plotting import Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and preparation <a name=\"Data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file\n",
    "df = pd.read_csv('bank_loans_100k.csv')\n",
    "\n",
    "# Checking dataset structure\n",
    "print(f\"Number of features:{df.shape[1]}\")\n",
    "print(f\"Number of instances:{df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duplicated_rows = df[df.duplicated()]\n",
    "duplicated_rows # No duplicates found within our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking features types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the distribution of numerical values. Duration and credit_amount are slightly left skewed whereas the other variables are slightly right skewed.\n",
    "Looking at the distribution of duration and credit_amount there is the chance that we have outliers.\n",
    "We will, however, not remove any outliners as we will scale our data later on in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the relationship between target variable and the other features.\n",
    "The feature \"class\" is going to be our target variable.\n",
    "A target value of 1 means the creditor should be classified as good(=solvent).\n",
    "A target value of 0 means the creditor should be classified as bad, and therefore is not elegible to receive the loan.\n",
    "We will comeback to the relationship between the target and the other variables later on in the notebook after we perfomed the necessary enconding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\"class\":\"target\"}, inplace = True)\n",
    "df[\"target\"].replace([\"good\", \"bad\"], [1,0], inplace=True)\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature engineering <a name=\"Feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Description <a name=\"Descr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Job:__  We assume that this feature is related to the monthly income of the creditors (with 0 representing a low paying job). | ordinary category (V0,V1,V2,V3) --> replaced by int in str\n",
    "\n",
    "__Checking_status:__  We assume it's the amount of the checking account. | ordinary category (V0,V1,V2,V3) --> replaced by int in str\n",
    "\n",
    "__Credit_history:__ We assume that this feature is to the credit history of the creditor (with 0 representing a bad credit history). | ordinary category (V0,V1,V2,V3,V4) --> replaced by int in str\n",
    "\n",
    "__Purpose:__ We assume that this feature represents the purpose of the loan (house loan, car loan ...) | (V0,V1,V2,V3,V4,V5,V6,V7,V8,V9,V10) --> replaced by one hot encoder (dummies)\n",
    "\n",
    "__Saving_status:__ We assume that this feature is related to the amount of savings the creditor has (with o representing no savings/little savings). | ordinary category (V0,V1,V2,V3,V4) --> replaced by int in str   \n",
    "\n",
    "\n",
    "__Employment:__ We assume that this feature is related to i) the type of job the creditor has (unemployed, retired, employed) or ii) the monthly income of the creditor from said job. In the second case, this would mean that this feature would be giving us the same information as the \"job\" feature. We will check this later in the notebook. | ordinary category (V0,V1,V2,V3,V4) --> replaced by int in str\n",
    "\n",
    "__Personal_status:__ We assume it describes the personal situation of an individual where the higher the number the more stable the individuals personal situation. | ordinary category (V0,V1,V2,V3,V4) --> replaced by one hot encode (dummies)\n",
    "\n",
    "__Other_parties:__ We assume it's the amount of parties involved in the loan. | ordinary category (V0,V1,V2) --> replaced by int in str\n",
    "\n",
    "__Property_magnitude:__ We assume that this feature is related to the amount of property the creditor owns (with 0 representing no property). | ordinary category (V0,V1,V2,V3) --> replaced by int in str\n",
    "\n",
    "__Other_payment_plans:__ We assume that this feature represents if the creditor has other payments plans(to banks, to stores or no other payment plans). | ordinary category (none, bank, stores) --> ordinary encoder\n",
    "\n",
    "__Housing:__ We assume that this feature represents i) the type of housing of the creditor (appartment, house...) or possibly if the creditor owns it or its rented. Later in the notebook we will compare this variable with the feature \"property_magnitude\" because we suspect there may by a potential relationship between these features due to their similar nature. | ordinary category (V0,V1,V2) --> replaced by int in str\n",
    "\n",
    "__Own_telephone:__ We assume that this feature represents if the creditor has a telephone or not. | binary (none, yes) --> one hot encoder\n",
    "\n",
    "__Foreign_worker:__ We assume that this feature represents if the creditor is a foreign worker or not. | binary (no, yes) --> one hot encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding <a name=\"Encoding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a lot of non-numerical features have the string \"V\" before a numeric value, we will remove the string and then convert the variables to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    if str(df[column].iloc[0]).startswith('V'):\n",
    "        df[column] = df[column].str.extract(r'[V](\\d)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting all features to numeric.\n",
    "\n",
    "We will use the pandas method \"to_numeric\" to  convert all varibales that are anonymized (even though we remove the \"V´s\"\n",
    "pandas still considers them categorical).\n",
    "\n",
    "We first start by transforming these 3 variables below first manually with numeric values, because otherwise we would get NaN values when using the \"to_numeric\" method (since this features are also categorical).\n",
    "\n",
    "On the feature \"other_payment_plans\" we assume that the information relevant to know is if the creditor has any other payments to do. Therefore \"banks\" and \"stores\" are represented by the same value.\n",
    "\n",
    "We encode dummies for the features \"purpose\" and \"personal_status\" since, unlike the other features that are ordinal, these represent categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"own_telephone\"].replace([\"yes\", \"none\"], [1,0], inplace=True)\n",
    "df[\"foreign_worker\"].replace([\"yes\", \"no\"], [1,0], inplace=True)\n",
    "df[\"other_payment_plans\"].replace([\"bank\", \"stores\", \"none\"], [1,1,0], inplace=True)\n",
    "\n",
    "features = df[[\"purpose\", \"personal_status\"]]\n",
    "df = pd.concat([df, pd.get_dummies(features)], axis=1)\n",
    "df.drop(columns=[\"purpose\", \"personal_status\"], inplace=True)\n",
    "\n",
    "categorical_features = df.select_dtypes(include=[object]).columns\n",
    "df[categorical_features] = df[categorical_features].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a closer look at each feature <a name=\"Taking\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start by analyzing the features \"employment\" and \"jobs\". \n",
    "We assume that these features are related to the monthly income of the creditors (with 0 representing a low paying job), and so these variables maybe be related in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"employment\"].value_counts(normalize=True).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"job\"].value_counts(normalize=True).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution plots we observe that the \"middle\" values (1, 2 & 3 for \"employment\" and 1,2 for \"job\") have the higest amount of samples,which may represent the creditors in the middle class \n",
    "(which is typically the class that makes most use of credit).\n",
    "Despite the fact they assume similar distributions, we decide not to drop any of the two features because their correlation is not strong enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Correlation:\",df[\"employment\"].corr(df[\"job\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another two features we suspect might be related to each other are \"property_magnitude\" and \"housing\". These might both represent the amount of property the creditors have (with 0 being no property/very cheap property)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"property_magnitude\"].value_counts(normalize=True).plot(kind = 'bar', color = \"limegreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"housing\"].value_counts(normalize=True).plot(kind = 'bar', color = \"limegreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance it doesn´t seem to exist a big relation between these 2 variables.\n",
    "After checking the correlation, we decide not to drop any of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Correlation:\",df[\"property_magnitude\"].corr(df[\"housing\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As to be observed below no compelling correlation exists between any of our features.\n",
    "\n",
    "Because there are no columns with a high enough correlation to the point where only one column could be kept, no columns were eliminated and we move forward with the df as is. However, later on in the notebook, when applying out models we will incldude  recursive feature elimination and thus figure out whether a dorpping some features would strenghten our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "corrMatrix=df.drop(columns='target').corr()\n",
    "sns.heatmap(corrMatrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Splitting the dataset <a name=\"Splitting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns='target')\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking target distribution.\n",
    "We have a fairly imbalance dataset. Since we have a big number of observations as it is, we will apply under sampling to randomly remove elements from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y.value_counts())\n",
    "y.value_counts(normalize = True).plot(kind = 'bar', color = \"darkkhaki\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Balancing -> Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "under = RandomUnderSampler(replacement=False ,random_state=0)\n",
    "X, y = under.fit_resample( X, y)\n",
    "\n",
    "print(y.value_counts())\n",
    "y.value_counts(normalize = True).plot(kind = 'bar', color = \"darkkhaki\") #The dataset is now balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset split -> 40% train, 40% validation, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X,y, random_state=42, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, random_state=42, test_size=0.995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training  <a name=\"Model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose Random Forest as it injects some stochasticity in how the splits are chosen, leading to a more effective \"randomness\".\n",
    "\n",
    "\n",
    "XGBoost was chosen because it is an optimized distributed gradient boosting library designed to be highly efficient with often having superior performance compared to other algorithms when applied to structured data.\n",
    "\n",
    "We decided to apply Logistic Regression as it is easy to understand and it requires less training. \n",
    "\n",
    "Nearest neighbours was chosen as it is a popular classifier and there are only two hyperparameter to be tuned.\n",
    "\n",
    "In all our models we apply RFE with the number of features at a minimum of 15 and a maximum of 34 as this equals the total number of features in our dataset.\n",
    "\n",
    "RandoizedSearch was chosen over GridSearch as it works more effectively on large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest <a name=\"Random\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()), \n",
    "                 ('RFE', RFE(DecisionTreeClassifier())), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'classifier': [RandomForestClassifier(random_state = 42)],\n",
    "              'scaler':[StandardScaler(), MinMaxScaler()],\n",
    "              'RFE__n_features_to_select': range(15,35,2),\n",
    "              'classifier__n_estimators': range(100,600,100), 'classifier__max_depth': range(5,11,1)}\n",
    "\n",
    "random_search_forest = RandomizedSearchCV(pipe, param_distributions=param_grid, cv=5, n_iter=20, scoring='precision') \n",
    "random_search_forest.fit(X_train, y_train)\n",
    "y_pred_forest=random_search_forest.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost <a name=\"XGB\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('RFE', RFE(DecisionTreeClassifier())), \n",
    "                 ('classifier', XGBClassifier(random_state = 42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'classifier': [XGBClassifier(random_state = 42)],\n",
    "              'scaler':[StandardScaler(), MinMaxScaler()],\n",
    "              'RFE__n_features_to_select': range(15,35,2),\n",
    "              'classifier__eta': [0.001, 0.01, 0.1], 'classifier__max_depth': range(5,11,1)}\n",
    "\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(pipe, param_distributions=param_grid, cv=5, n_iter=20, scoring='precision') \n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb=random_search_xgb.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression <a name=\"Logistic\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test only L2 regularization as L1 is not supported. Lower values of C were choosen to iterate as it allows for stronger regularization, hence it can enhance our performance on unseen data which is exactly what we try to achive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('RFE', RFE(DecisionTreeClassifier())),\n",
    "                 ('classifier', LogisticRegression(random_state = 42, penalty = 'l2'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'classifier': [LogisticRegression(random_state = 42, penalty = 'l2')],\n",
    "              'scaler':[StandardScaler(), MinMaxScaler()],\n",
    "              'RFE__n_features_to_select': range(15,35,2),\n",
    "              'classifier__C': [0.01,0.1,1]}\n",
    "\n",
    "random_search_logreg = RandomizedSearchCV(pipe, param_distributions=param_grid, cv = 5, n_iter = 20, scoring='precision')\n",
    "random_search_logreg.fit(X_train, y_train)\n",
    "y_pred_logreg=random_search_logreg.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbors <a name=\"Nearest\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('RFE', RFE(DecisionTreeClassifier())),\n",
    "                 ('classifier', KNeighborsClassifier(n_neighbors = ()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'classifier': [KNeighborsClassifier(n_neighbors = ())], \n",
    "              'scaler':[StandardScaler(), MinMaxScaler()],\n",
    "              'RFE__n_features_to_select': range(15,35,2),\n",
    "              'classifier__n_neighbors': range(19, 31,2)}\n",
    "\n",
    "random_search_kn = RandomizedSearchCV(pipe, param_distributions=param_grid, cv = 5, n_iter = 20, scoring='precision')\n",
    "random_search_kn.fit(X_train, y_train)\n",
    "y_pred_kn=random_search_kn.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model determination <a name=\"Model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest <a name=\"Random2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters: ', random_search_forest.best_params_)\n",
    "print('Precision is', precision_score(y_val, y_pred_forest))\n",
    "print('F1 score is', f1_score(y_val, y_pred_forest))\n",
    "print('Recall is', recall_score(y_val, y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost <a name=\"XGB2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters: ', random_search_xgb.best_params_)\n",
    "print('Precision is', precision_score(y_val, y_pred_xgb))\n",
    "print('F1 score is', f1_score(y_val, y_pred_xgb))\n",
    "print('Recall is', recall_score(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression <a name=\"Logistic2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters: ', random_search_logreg.best_params_)\n",
    "print('Precision is', precision_score(y_val, y_pred_logreg))\n",
    "print('F1 score is', f1_score(y_val, y_pred_logreg))\n",
    "print('Recall is', recall_score(y_val, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbors <a name=\"Nearest2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Best parameters: ', random_search_kn.best_params_)\n",
    "print('Precision is', precision_score(y_val, y_pred_kn))\n",
    "print('F1 score is', f1_score(y_val, y_pred_kn))\n",
    "print('Recall is', recall_score(y_val, y_pred_kn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As aformentioned it would be more costly for a a bank to give out a loan to a potential defaulter in comparison to not giving out a loan to a good creditor. Thus, in order to achieve a low type II error we need to maximize our precision score and therefore we chose that as our metric to determine the best model. \n",
    "\n",
    "Below we computed a function that retrieves the best model based on the above printed outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "     \"randomforest\": random_search_forest,\n",
    "     \"xgboost\": random_search_xgb,\n",
    "     \"logistic_regression\": random_search_logreg,\n",
    "     \"nearest_neighbours\": random_search_kn\n",
    " }\n",
    "\n",
    "precision_scores= {\n",
    "    \"random_forest\": f1_score(y_val, y_pred_forest),\n",
    "    \"xgboost\": f1_score(y_val, y_pred_xgb),\n",
    "    \"logistic_regression\": f1_score(y_val, y_pred_logreg),\n",
    "    \"nearest_neighbours\": f1_score(y_val, y_pred_kn)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred_kn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leading_model():\n",
    "    for a, b in models.items():\n",
    "        if max(precision_scores, key = precision_scores.get) == a:\n",
    "            best = b\n",
    "            \n",
    "    return best.best_params_\n",
    "\n",
    "model = leading_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation <a name=\"Test\"></a>\n",
    "\n",
    "After selecting and tuning our model on the train set, we evaluated its performance on the validation set and apply it to the test set. Based on the precision score we determined that our best model is the XGBoost classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe = Pipeline([('scaler', model['scaler']),\n",
    "                       ('RFE', RFE(DecisionTreeClassifier(), n_features_to_select = model['RFE__n_features_to_select'])), \n",
    "                       ('classifier', model['classifier'])])\n",
    "\n",
    "final_pipe.fit(X_train, y_train)\n",
    "y_pred_final=final_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_pred_final)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we plotted a confusion matrix, the classification report and the ROC-curve. As aformentioned in our business problem the type II error is more costly. Hence, it is important to emphasize the number of false positives. Our model predicted a total of 1377 of creditors that were labeled solvent but in fact were not. \n",
    "\n",
    "Tying in to the false positive number we have the precision score. The classification report shows 77% of the creditors that were labeled solvent were in fact creditworthy. Furthermore, our recall score shows that we were able to identify around 78% of the good creditors present in our test set.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis <a name=\"Feature2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_pipe = permutation_importance(final_pipe, X_train, y_train, n_repeats=30, random_state=42)\n",
    "feat_import_gini = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_gini)), feat_import_gini, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_gini)), xticklabels=X_train.columns)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the permutation feature importance plot it can be noticed that checking status and credit history are ammong the most important features of our model. The purpose and personal status dummy features seem at first glance not as important to our model although this could due to the fact that they are correlated with other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train=X_train.copy()\n",
    "Xy_train['target'] = y_train\n",
    "fig, axes, summary_df = info_plots.target_plot(\n",
    "df=Xy_train, feature='credit_history', feature_name='credit_history', target='target', show_percentile=True, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the credit_history plot we come to a very rational conclusion: a better credit history leads to a bigger probability of the creditor being solvent and therefore belonging to class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train=X_train.copy()\n",
    "Xy_train['target'] = y_train\n",
    "fig, axes, summary_df = info_plots.target_plot(\n",
    "df=Xy_train, feature='checking_status', feature_name='checking_status', target='target', show_percentile=True, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The checking status plot also a very logical behaviour as it indicates that a higher value in checking status lead to a higher probability of the creditor belonging to class 1 and thus being classified as solvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train=X_train.copy()\n",
    "Xy_train['target'] = y_train\n",
    "fig, axes, summary_df = info_plots.target_plot(\n",
    "df=Xy_train, feature='age', feature_name='age', target='target', show_percentile=True, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot we conclude that higher values in age generally leads to a bigger probability of the creditor belonging to class 1. This makes sense because, from the point of view of the banks, younger people may not be as stable in terms of their personal and financial situations when compared to more mature people.\n",
    "\n",
    "However, we dont observe this trend in the last percentile. The most logical explanation for this trend is that, since this percentile starts around the age of 50, the creditors are getting close to retirement status which tipically comes with a loss in monthly income. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train=X_train.copy()\n",
    "Xy_train['target'] = y_train\n",
    "fig, axes, summary_df = info_plots.target_plot(\n",
    "df=Xy_train, feature='installment_commitment', feature_name='installment_commitment', target='target', show_percentile=True, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main takeaway from the installment_commitment plot its an obvious one: the bigger the value of the installment commitment that the creditor has to pay, the less likelihood the person belongs to class 1. This can happen because the bank considered the creditor riskier and so the interest rate to be paid is bigger, or for the fact that the creditor has less capital himself and so has to borrow a bigger amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks <a name=\"Neural\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the neural networks we will apply keras tuner in order to tune our hyperparameters. As we have a binary classification problem the last layer will apply sigmoid as the activation method. Additionally, we used precision as our evaluation metric due to our business problem and we also implement early stopping to minimize the training time of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous model application we scaled the data within the pipeline. Therefore, we scale the data seperately before training the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = initializers.HeNormal()\n",
    "\n",
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "\n",
    "  for i in range(hp.Int('num_layers', 1, 4)): \n",
    "      model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=34, max_value=136,  step=34), activation='relu',\n",
    "                                            kernel_initializer=initializer,\n",
    "                                            kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "\n",
    "  model.add(layers.Dense(1, activation='sigmoid', kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=[tf.keras.metrics.Precision(name='precision')]\n",
    "  )\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.metrics\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective= kt.Objective('val_precision', direction = 'max'),\n",
    "    max_trials=10,\n",
    "    project_name='simple_classification',\n",
    "    overwrite=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train_scaled, y_train, callbacks = [early_stopping_cb], epochs=40, validation_data=(X_val_scaled, y_val))\n",
    "best_model = tuner.get_best_models()[0]\n",
    "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss/precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above we can see a positive outcome when it comes to our training loss as well as the validation loss because it slightly decreases over time. \n",
    "\n",
    "However, in terms of precision, our training precision remains at a constant level while our validation precision shows a wide range of outputs.\n",
    "\n",
    "Another important factor to notice is that the precision curves are not that close to each other. This could be a sign of of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Audit <a name=\"Bias\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_array = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.DataFrame(X_test, columns=X_val.columns)\n",
    "X_train=pd.DataFrame(X_train, columns=X_train.columns)\n",
    "aequitas = X_test.filter(items=['foreign_worker'])\n",
    "aequitas['Foreign_worker'] = aequitas['foreign_worker'].apply(lambda x: \"Y\" if x == 1 else \"N\")\n",
    "aequitas[\"label_value\"] = y_test_array\n",
    "aequitas[\"score\"] = y_pred_final\n",
    "df1 = aequitas.drop(columns=['foreign_worker'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Group()\n",
    "xtab, _ = g.get_crosstabs(df1)\n",
    "xtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp = Plot()\n",
    "fpr = aqp.plot_group_metric(xtab, 'fpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Bias()\n",
    "bdf = b.get_disparity_predefined_groups(xtab, original_df=df1, ref_groups_dict={'Foreign_worker':'N'}, alpha=0.05, mask_significance=True)\n",
    "calculated_disparities = b.list_disparities(bdf)\n",
    "disparity_significance = b.list_significance(bdf)\n",
    "bdf[['attribute_name', 'attribute_value'] + calculated_disparities + disparity_significance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp.plot_disparity(bdf, group_metric='ppr_disparity', attribute_name='Foreign_worker', significance_alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the bias table and the plot above we observe the disparity ratio (fpr_disparity) and very easy conclude that foreign workers are falsely denied the loan almost 25 times more when compared to non-foreign workers. However, even with eliminating the feature from our dataset we could still be affected by bias as the variable in question could be correlated to other variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final conclusion and remarks <a name=\"Conclusion\"></a>\n",
    "In this notebook we implemented different approaches to determine whether a creditor would be solvent or not. As mentioned through our work the type II error was the most costly one and we therefore tried to maximize precision score. In the end the model chosen was the XGBoost classifier which allowed us to identify 77% of the creditors that were actually labeled solvent.\n",
    "\n",
    "After applying the model we also checked for feature importance and came to the conlusion that checking status and credit history where some of the most important variables in our model. For this features in particular we also looked at how a different range of values has affected our target and deem it to be plausible and rational.\n",
    "\n",
    "Subsequently, we trained a neural network model on our data. We had mixed results regarding the precision score, however, our loss for the training ad validation data deacreased over the different epochs.\n",
    "\n",
    "In addition to analysing the metrics we studied whether or not our dataset suffered from potential bias. From the work performed we can easily extract that the feature foreign worker shows sign of strong bias. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
